"use strict";(self.webpackChunkdocs_temp=self.webpackChunkdocs_temp||[]).push([[796],{8064:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"welcome-llm-docs","metadata":{"permalink":"/Isolated-Local-LLM-Deployment-Monitoring-Stack/blog/welcome-llm-docs","editUrl":"https://github.com/mohamedaminehamdi/Isolated-Local-LLM-Deployment-Monitoring-Stack/tree/main/docs/blog/2024-01-01-welcome.md","source":"@site/blog/2024-01-01-welcome.md","title":"Welcome to the LLM Stack Documentation \ud83c\udf89","description":"We\'re excited to launch the official documentation site for the Isolated Local LLM Deployment & Monitoring Stack!","date":"2024-01-01T00:00:00.000Z","tags":[{"inline":true,"label":"llm","permalink":"/Isolated-Local-LLM-Deployment-Monitoring-Stack/blog/tags/llm"},{"inline":true,"label":"docker","permalink":"/Isolated-Local-LLM-Deployment-Monitoring-Stack/blog/tags/docker"},{"inline":true,"label":"monitoring","permalink":"/Isolated-Local-LLM-Deployment-Monitoring-Stack/blog/tags/monitoring"},{"inline":true,"label":"documentation","permalink":"/Isolated-Local-LLM-Deployment-Monitoring-Stack/blog/tags/documentation"}],"readingTime":1.36,"hasTruncateMarker":true,"authors":[{"name":"LLM Stack Team","title":"Documentation Team","image_url":"https://github.com/ghost.png","imageURL":"https://github.com/ghost.png","socials":{},"key":null,"page":null}],"frontMatter":{"slug":"welcome-llm-docs","title":"Welcome to the LLM Stack Documentation \ud83c\udf89","authors":[{"name":"LLM Stack Team","title":"Documentation Team","image_url":"https://github.com/ghost.png","imageURL":"https://github.com/ghost.png"}],"tags":["llm","docker","monitoring","documentation"]},"unlisted":false},"content":"We\'re excited to launch the official documentation site for the **Isolated Local LLM Deployment & Monitoring Stack**! \\n\\n## \ud83d\ude80 What\'s New\\n\\nThis comprehensive documentation site provides:\\n\\n- **Step-by-step guides** for deploying your local LLM environment\\n- **Detailed monitoring setup** with Prometheus and Grafana\\n- **Security best practices** for air-gapped deployments\\n- **Troubleshooting guides** for common issues\\n\\n\x3c!-- truncate --\x3e\\n\\n## \ud83d\udcda Documentation Structure\\n\\nOur documentation is organized into clear sections:\\n\\n### \ud83c\udfaf [Getting Started](../docs/intro)\\nJump right in with our quick start guide. Get your LLM environment running in under 5 minutes!\\n\\n### \ud83d\udd27 [LLM Deployment](../docs/llm-deployment)\\nDeep dive into Ollama configuration, model management, and Open WebUI setup.\\n\\n### \ud83d\udcca [Monitoring Stack](../docs/monitoring)\\nLearn how to set up comprehensive monitoring with Prometheus, Grafana, cAdvisor, and Node Exporter.\\n\\n### \ud83d\udd12 [Security & Isolation](../docs/security)\\nUnderstand the security features and network isolation that make this stack enterprise-ready.\\n\\n### \ud83d\udee0\ufe0f [Troubleshooting](../docs/troubleshooting)\\nFind solutions to common issues and learn debugging techniques.\\n\\n## \ud83c\udf1f Key Features Covered\\n\\n- **One-command deployment** with Docker\\n- **Air-gapped compatibility** for secure environments\\n- **Real-time monitoring** and alerting\\n- **Model management** and optimization\\n- **Performance tuning** and resource management\\n\\n## \ud83e\udd1d Contributing\\n\\nFound an issue with the documentation? Have suggestions for improvement?\\n\\n- [Report issues](https://github.com/mohamedaminehamdi/Isolated-Local-LLM-Deployment-Monitoring-Stack/issues)\\n- [Join discussions](https://github.com/mohamedaminehamdi/Isolated-Local-LLM-Deployment-Monitoring-Stack/discussions)\\n- [Contribute to docs](https://github.com/mohamedaminehamdi/Isolated-Local-LLM-Deployment-Monitoring-Stack/tree/main/docs)\\n\\n## \ud83c\udfaf What\'s Next?\\n\\nWe\'re continuously improving the documentation based on community feedback. Upcoming additions include:\\n\\n- **Advanced configuration guides**\\n- **Performance optimization tutorials**\\n- **Custom model integration**\\n- **Scaling strategies**\\n\\nReady to get started? Head over to our [Getting Started Guide](../docs/intro) and deploy your first LLM in minutes!\\n\\n---\\n\\nHappy deploying! \ud83d\ude80"}]}}')}}]);